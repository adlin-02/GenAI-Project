
# RAG â€“ Poetry-based Retrieval Augmented Generation System

RAG is a domain-specific Retrieval-Augmented Generation (RAG) pipeline that enables semantic understanding and generation of responses over poetic documents. It leverages language model embeddings, vector search using Weaviate, and a custom retriever-generator architecture to produce context-aware outputs.

---

## ğŸ“Œ Objectives

- Enable semantic search across poetic content using embeddings.
- Retrieve relevant poetic chunks for a given question using vector similarity.
- Use large language models (LLMs) to generate answers based on retrieved context.
- Evaluate the quality of generated answers using custom metrics.

---

## ğŸš€ Features

âœ… Poetry document chunking and preprocessing  
âœ… Embedding generation using LLMs  
âœ… Vector storage in Weaviate for semantic retrieval  
âœ… Question answering using LLM + context  
âœ… Evaluation with quantitative and qualitative analysis  
âœ… Modular and extensible architecture

---

## ğŸ—‚ï¸ Project Structure

```
teenuRag/
â”‚
â”œâ”€â”€ app.py                     # Main pipeline controller
â”œâ”€â”€ chunk_poems.py             # Splits poems into chunks for embedding
â”œâ”€â”€ generate_embeddings.py     # Generates embeddings for chunks
â”œâ”€â”€ ingest_to_weaviate.py      # Ingests chunks & embeddings into Weaviate
â”œâ”€â”€ retriever_generator.py     # Retrieves and generates answers
â”œâ”€â”€ poetry_rag_core.py         # Core business logic for RAG
â”œâ”€â”€ evaluate_rag.py            # Evaluates answer quality
â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ data/                      # Raw poetry documents
â”œâ”€â”€ embeddings/                # Stored embeddings
â”œâ”€â”€ evaluation/                # Evaluation data and results
â”œâ”€â”€ output_chunks/             # Normalized & preprocessed chunks
â”œâ”€â”€ .env                       # API keys and configuration
```

---

## ğŸ“¥ Installation

1. **Clone the Repository**

```bash
git clone https://github.com/yourusername/Rag.git
cd Rag
```

2. **Install Dependencies**

```bash
pip install -r requirements.txt
```

3. **Configure Environment Variables**

Create a `.env` file:

```env
OPENAI_API_KEY=your_openai_api_key
WEAVIATE_ENDPOINT=http://localhost:8080
```

---

## ğŸ§ª Workflow

### Step 1: Chunk Documents

```bash
python chunk_poems.py
```

### Step 2: Generate Embeddings

```bash
python generate_embeddings.py
```

### Step 3: Ingest to Weaviate

```bash
python ingest_to_weaviate.py
```

### Step 4: Ask Questions

```bash
python app.py
```

### Step 5: Evaluate the System

```bash
python evaluate_rag.py
```

---

## ğŸ“Š Evaluation

Evaluation is done using a set of curated QA pairs and the results are stored in:

- `evaluation/evaluation_data.json`
- `evaluation/evaluation_report.json`

Metrics include:

- Embedding similarity
- Response relevance score
- Exact match / partial match

---

## âš™ï¸ Tech Stack

- **Python 3.10+**
- **OpenAI API** â€“ for embedding & generation
- **Weaviate** â€“ vector DB for retrieval
- **LangChain / custom RAG logic**
- **dotenv** â€“ for config management

---

## ğŸ“„ Sample Use Case

> **Question:** *"What does the poet suggest about hope in doc 3?"*  
> **Response:** *(based on doc 3)* "The poet conveys hope as an internal spark that survives even in the harshest of times..."

---

## ğŸ”“ License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## ğŸ‘©â€ğŸ’» Author

**Adlin Teenu X**   
August 2025

Project inspired by the intersection of AI and creative literature. Built as part of an exploratory RAG implementation using poetic content.

---

## ğŸ™Œ Acknowledgements

- OpenAI for LLM APIs
- Weaviate team for open-source vector DB
- Community behind RAG and LangChain

---
